# -*- coding: utf-8 -*-
"""programming_dhcss_exercise_w5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rujBO1uxZSnq_QwnWK0dzV6e3Em9UhDm

Programming for DHCSS Exercises: Week 5. Dictionaries, Sets, JSON
"""

### Problem 1 ###

### First download data

import pandas as pd

url = 'https://raw.githubusercontent.com/taegyoon-kim/programming_dhcss_23fw/main/week_5/digital_media_comments.csv'
df = pd.read_csv(url)


### Problem 1a: Which platform has most unique users?

### Hint: From the columns in the Pandas dataframe, create sets for respective platforms

### Hint: Here is a quick summary of how to subset rows conditional on a column from a Pandas dataframe

df_fb = df[df['Platform'] == 'Facebook'] # return rows whose value for the "Platform" column is "Facebook"
df_fb['Identifier'] # access "Identifier" column

### Write your code here


### Problem 1b: Which platform has most unique users whose posts are flagged as hateful?

### Hint: When you need multiple conditions to subset data from a Pandas dataframe, connect them using '&'

### Write your code here


### Problem 1c: Get the numbers of 1) the users who have commented on both Facebook and Twitter 2) the users who have commneted on Instagram but not on YouTube

### Write your code here


### Problem 1d: Generate a nested dictionary with each inner dictionary representing a unique user, where the values inside the inner dictionaries represent the number of comments from each platform

### Start with a subset of the data for hateful posts

df_hate = df[df['Flagged_Hateful'] == 'Yes']

### Hint: Use df.iterrows() (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html)

### Write your code here

### Problem 2 ###

### Problem 2a: Join the following dictionaries (keep the orgiianl dictionaries intact though!)

dict1 = {'Japan': 'Tokyo', 'U.S.A.': 'Washington D.C.', 'Indonesia': 'Jarkarta'}
dict2 = {'Canada': 'Ottawa', 'South Korea': 'Seoul', 'China': 'Beijing'}

### Hint: Check the following link for methods like copy() or update() (https://www.programiz.com/python-programming/methods/dictionary/copy)

### Write your code here


### Problem 2b: Create a new dictionary where the keys are capitals and the values are their corresponding countries

### Hint: Use dictionary comprehension

### Write your code here

### Problem 3 ###

### The following lists contain some data about architets and their works

architects = [
    'Frank Lloyd Wright',
    'Le Corbusier',
    'Zaha Hadid',
    'Norman Foster',
    'Renzo Piano',
    'Buckminster Fuller',
    'Philip Johnson',
    'I. M. Pei',
    'Frank Gehry',
    'Alvar Aalto',
    'Louis Sullivan',
    'Rem Koolhaas',
    'Antoni Gaudí',
    'Ludwig Hilberseimer'
]

works = [
    'Fallingwater',
    'Villa Savoye',
    'London Aquatics Centre',
    'The Gherkin',
    'The Shard',
    'Geodesic Dome',
    'The Glass House',
    'Louvre Pyramid',
    'Guggenheim Museum Bilbao',
    'Villa Mairea',
    'Wainwright Building',
    'CCTV Headquarters',
    'Sagrada Família',
    'LaFayette Park'
]

birth_years = [
    1867, 1887, 1950, 1935, 1937, 1895, 1906, 1917, 1929, 1898, 1856, 1944, 1852, 1885
]

### Problem 3a: Convert the first two lists into a dictionary (architect-work pairs)

### Write your code here


### Problem 3b: Repeat but 1a but only include architect born after 1901

### Write your code here


### Problem 3c: Using a dictionary, count the number of architects whose last names start with the same letter

### Hint: Each key would be the last name, and the corresponding value would be the number of times the last name appear in the data

### Write your code here

### Problem 4 ###

### Let's read a JSON file for tweets written by Tulsi Gabbard, a former U.S. House member
### The following code will return a list of dictionaries with each dictionary representing a tweet

import requests
import json

url = "https://raw.githubusercontent.com/taegyoon-kim/programming_dhcss_23fw/main/week_5/RepAdamSmith.json"
response = requests.get(url) # send a GET request to fetch the JSON data

lines = response.text.splitlines() # help(str.splitlines)

l_tweets = []

for line in lines:
    try:
        tweet = json.loads(line)
        l_tweets.append(tweet)
    except json.JSONDecodeError as e:
        print(e)

print(f"Loaded {len(l_tweets)} JSON objects successfully.")


### Problem 4a: From the list of dictionaries, create a Pandas dataframe containing "text", "id_str", " and "favorite_count" as columns

### Hint I: You can use try-except to handle situations where the key you are looking for does not exist in the dictionary

### Hint II: Loop through dictionaries (tweets) in "l_tweets"

### Hint III: At each iteration, create a small dictionary containg the required keys and append it to an empty list

### Write your code here


### Problem 4b: See what the get() dictionary method does: https://www.geeksforgeeks.org/python-dictionary-get-method/

### Use this method instead of try-except

### Write your code here