# -*- coding: utf-8 -*-
"""programming_dhcss_exercise_w5_solution

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mS46v6nJJ8rrxI2TwDnp3e2nkMocgvPA

Programming for DHCSS Exercises: Week 5. Dictionaries, Sets, JSON
"""

### Problem 1 ###

### First download

import pandas as pd

url = 'https://raw.githubusercontent.com/taegyoon-kim/programming_dhcss_23fw/main/week_5/digital_media_comments.csv'
df = pd.read_csv(url)


### Problem 1a: Which platform has most unique users?

### Hint: From the columns in the Pandas dataframe, create sets for respective platforms

### Hint: Here is a quick summary of how to subset data from a Pandas dataframe

df_fb = df[df['Platform'] == 'Facebook'] # return rows whose value for the Platform column is "Facebook"
df_fb['Identifier']

### Write your code here

print(df['Platform'].value_counts()) # (non-unique) users by platform
ids_fb = set(df[df['Platform'] == 'Facebook']['Identifier'])
ids_yt = set(df[df['Platform'] == 'YouTube']['Identifier'])
ids_twt = set(df[df['Platform'] == 'Twitter']['Identifier'])
ids_ig = set(df[df['Platform'] == 'Instagram']['Identifier'])
[len(i) for i in (ids_fb, ids_yt, ids_twt, ids_ig)]


### Problem 1b: Which platform has most unique users whose posts are flagged as hateful?

### Hint: When you need multiple conditions to subset data from a Pandas dataframe, connect them using '&'

### Write your code here

df_hate_fb = df[(df['Flagged_Hateful'] == 'Yes') & (df['Platform'] == 'Facebook')]
df_hate_yt = df[(df['Flagged_Hateful'] == 'Yes') & (df['Platform'] == 'YouTube')]
df_hate_twt = df[(df['Flagged_Hateful'] == 'Yes') & (df['Platform'] == 'Twitter')]
df_hate_ig = df[(df['Flagged_Hateful'] == 'Yes') & (df['Platform'] == 'Instagram')]

print(len(set(df_hate_fb['Identifier'])))
print(len(set(df_hate_yt['Identifier'])))
print(len(set(df_hate_twt['Identifier'])))
print(len(set(df_hate_ig['Identifier'])))


### Problem 1c: Get the numbers of 1) the users who have commented on both Facebook and Twitter 2) the users who have commneted on Instagram but not on YouTube

### Write your code here

print(len(ids_ig.difference(ids_yt)))
print(len(ids_fb.union(ids_twt)))


### Problem 1d: Generate a nested dictionary with each inner dictionary representing a unique user,
### where the values inside the inner dictionaries represent the number of comments from each platform

### Start with a subset of the data for hateful posts

df_hate = df[df['Flagged_Hateful'] == 'Yes']

### Hint: Use df.iterrows() (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html)

### Write your code here

user_dict = dict()

for index, row in df_hate.iterrows():

    id = row['Identifier']

    # if user is not in the dictionary, create an inner dictinoary (adding them as a key in the outer dictionary)
    if id not in user_dict:
      user_dict[id] = {}

    platform = row['Platform']

    # if platform is not in the user's sub-dictionary, add it with count 1
    if platform not in user_dict[id]:
      user_dict[id][platform] = 1
    # otherwise, increment the count by 1
    else:
      user_dict[id][platform] += 1

len(user_dict.keys()) == len(set(df_hate['Identifier']))

### Problem 2 ###

### Problem 2a: Join the following dictionaries (keep the orgiianl dictionaries intact though!)

dict1 = {'Japan': 'Tokyo', 'U.S.A.': 'Washington D.C.', 'Indonesia': 'Jarkarta'}
dict2 = {'Canada': 'Ottawa', 'South Korea': 'Seoul', 'China': 'Beijing'}

### Hint: Check the following link for methods like copy() or update() (https://www.programiz.com/python-programming/methods/dictionary/copy)

### Write your code here

merged_dict = dict1.copy()
merged_dict.update(dict2)

print(merged_dict)

### Problem 2b: Create a new dictionary where the keys are capitals and the values are their corresponding countries

### Hint: Use dictionary comprehension

### Write your code here

inverted_dict = {capital: country for country, capital in merged_dict.items()}

### Problem 3 ###

### The following lists contain some data about architets and their works

architects = [
    'Frank Lloyd Wright',
    'Le Corbusier',
    'Zaha Hadid',
    'Norman Foster',
    'Renzo Piano',
    'Buckminster Fuller',
    'Philip Johnson',
    'I. M. Pei',
    'Frank Gehry',
    'Alvar Aalto',
    'Louis Sullivan',
    'Rem Koolhaas',
    'Antoni Gaudí',
    'Ludwig Hilberseimer'
]

works = [
    'Fallingwater',
    'Villa Savoye',
    'London Aquatics Centre',
    'The Gherkin',
    'The Shard',
    'Geodesic Dome',
    'The Glass House',
    'Louvre Pyramid',
    'Guggenheim Museum Bilbao',
    'Villa Mairea',
    'Wainwright Building',
    'CCTV Headquarters',
    'Sagrada Família',
    'LaFayette Park'
]

birth_years = [
    1867, 1887, 1950, 1935, 1937, 1895, 1906, 1917, 1929, 1898, 1856, 1944, 1852, 1885
]

### Problem 3a: Convert the first two lists into a dictionary (architect-work pairs)

### Write your code here

dict(zip(architects, works))

architect_dict = {architect: work for architect, work in zip(architects, works)}



### Problem 3b: Repeat but 1a but only include architect born after 1901

### Write your code here

architect_dict_cond = {architect: work for architect, work, birth_year in zip(architects, works, birth_years) if birth_year > 1901}
print(architect_dict_cond)
print(len(architect_dict_cond))



### Problem 3c: Using a dictionary, count the number of architects whose last names start with the same letter

### Hint: Each key would be the last name, and the corresponding value would be the number of times the last name appear in the data

### Write your code here

first_name_initials = {}

for architect in architects:
    initial = architect.split()[-1][0]  # first letter of the first name
    if initial in first_name_initials:
        first_name_initials[initial] += 1
    else:
        first_name_initials[initial] = 1

print(first_name_initials)

### Problem 4 ###

### Let's read a JSON file for tweets written by Tulsi Gabbard, a former U.S. House member
### The following code will return a list of dictionaries with each dictionary representing a tweet

import requests
import json

url = "https://raw.githubusercontent.com/taegyoon-kim/programming_dhcss_23fw/main/week_5/RepAdamSmith.json"
response = requests.get(url) # send a GET request to fetch the JSON data

lines = response.text.splitlines() # help(str.splitlines)

l_tweets = []

for line in lines:
    try:
        tweet = json.loads(line)
        l_tweets.append(tweet)
    except json.JSONDecodeError as e:
        print(e)

print(f"Loaded {len(l_tweets)} JSON objects successfully.")


### Problem 4a: From the list of dictionaries, create a Pandas dataframe containing "text", "id_str", " and "favorite_count" as columns

### Hint I: You can use try-except to handle situations where the key you are looking for does not exist in the dictionary

### Hint II: Loop through dictionaries (tweets) in "l_tweets"

### Hint III: At each iteration, create a small dictionary containg the required keys and append it to an empty list

### Write your code here

data_list_try_except = []

for tweet in l_tweets:

    data_dict = {}

    try:
        data_dict['text'] = tweet['text']
    except KeyError:
        data_dict['text'] = None

    try:
        data_dict['id_str'] = tweet['id_str']
    except KeyError:
        data_dict['id_str'] = None

    try:
        data_dict['favorite_count'] = tweet['favorite_count']
    except KeyError:
        data_dict['favorite_count'] = None

    data_list_try_except.append(data_dict)

df_tweets_try_except = pd.DataFrame(data_list_try_except)


### Problem 4b: See what the get() dictionary method does: https://www.geeksforgeeks.org/python-dictionary-get-method/

### Use this method instead of try-except

### Write your code here

data_list_get = []

for tweet in l_tweets:
    data_dict = {
        'text': tweet.get('text', None),
        'id_str': tweet.get('id_str', None),
        'favorite_count': tweet.get('favorite_count', None)
    }
    data_list_get.append(data_dict)

df_tweets_get = pd.DataFrame(data_list_get)