{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tWIaVY4EotA"
      },
      "source": [
        "Programming for DHCSS Exercises: Week 10. Data Visualization\n",
        "\n",
        "(coppied/adapted from [Pierian Data](https://github.com/mwesterby/complete-python-bootcamp/blob/main/11.%20Web%20Scraping/11.3%20Web%20Scraping%20Exercises.ipynb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PUhSB9WvEotB"
      },
      "outputs": [],
      "source": [
        "### Problem 1: Import any libraries you think you'll need to scrape a website\n",
        "\n",
        "### Write your code here\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fDSgQABIEotC"
      },
      "outputs": [],
      "source": [
        "### Problem 2: Connect to http://quotes.toscrape.com/ and get the HMTL text from the page\n",
        "\n",
        "### Write your code here\n",
        "\n",
        "res = requests.get('http://quotes.toscrape.com/')\n",
        "soup = BeautifulSoup(res.text)\n",
        "soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fg246i6gEotE"
      },
      "outputs": [],
      "source": [
        "### Problem 3: Get the names of all the authors on the first page\n",
        "\n",
        "### Write your code here\n",
        "\n",
        "authors = []\n",
        "author_tags = soup.find_all('small')\n",
        "for i in author_tags:\n",
        "  authors.append(i.text)\n",
        "\n",
        "authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx8AyYzmEotF"
      },
      "outputs": [],
      "source": [
        "### Problem 4: Create a list of all the quotes on the first page\n",
        "\n",
        "### Write your code here\n",
        "\n",
        "quotes = []\n",
        "text_tags = soup.find_all(class_ = 'text')\n",
        "for i in text_tags:\n",
        "    quotes.append(i.text)\n",
        "\n",
        "quotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efSgs0hvEotG"
      },
      "source": [
        "Now, note that there are more than one page, and subsequent pages look like: http://quotes.toscrape.com/page/2/\n",
        "- You will need to figure out how to check that your loop is on the last page with quotes\n",
        "- For the sake of our exercise, note that we have 10 pages\n",
        "- Pages exist after 10 but look like: http://quotes.toscrape.com/page/11/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sTtrACyEotH"
      },
      "outputs": [],
      "source": [
        "### Problem 5: Loop through all the pages and get all the unique authors on the website\n",
        "\n",
        "### Write your code here\n",
        "\n",
        "current_page = 1\n",
        "authors = []\n",
        "\n",
        "while True:\n",
        "\n",
        "  print(current_page)\n",
        "  url = f'http://quotes.toscrape.com/page/{current_page}/'\n",
        "\n",
        "  res = requests.get(url)\n",
        "  soup = BeautifulSoup(res.text)\n",
        "  author_tags = soup.find_all('small')\n",
        "\n",
        "  if len(author_tags) == 0:\n",
        "    break\n",
        "\n",
        "  for author in author_tags:\n",
        "      authors.append(author.text)\n",
        "\n",
        "  current_page += 1\n",
        "\n",
        "for author in authors:\n",
        "    print(author)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}